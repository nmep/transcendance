input {
  tcp {
    port => 514
    type => "tcp-syslog"
  }
}

filter {
  # First, try to parse the incoming message as JSON.
  json {
    source => "message"
    # If JSON parsing fails, the original "message" field remains unchanged.
  }

  grok {
    match => { "message" => [
      # [1] Grafana logs (starting with "logger=" key/value pairs)
      '^logger=%{DATA:logger}\s+t=%{TIMESTAMP_ISO8601:log_time}\s+level=%{WORD:level}\s+msg="(?<log_msg>[^"]+)"(?:\s+id="(?<migration_id>[^"]+)")?(?:\s+user=%{DATA:user})?(?:\s+duration=%{DATA:duration})?.*$',
      
      # [2] Grafana alternative (if in key/value style starting with "t=")
      '^t=%{TIMESTAMP_ISO8601:timestamp}\s+lvl=%{WORD:level}\s+msg="(?<message>[^"]+)"(?:\s+logger=%{DATA:logger})?(?:\s+service=%{WORD:service})?.*$',
      
      # [3] Kibana logs (JSON-like key/value)
      '^\{\s*"@timestamp"\s*=>\s*%{TIMESTAMP_ISO8601:timestamp},\s*"severity"\s*=>\s*"%{WORD:severity}",\s*"time"\s*=>\s*"%{DATA:sys_time}",\s*"message"\s*=>\s*"%{GREEDYDATA:msg}",\s*"type"\s*=>\s*"%{WORD:type}",\s*"service"\s*=>\s*"%{WORD:service}"\s*\}$',

      # [4] Elastic logs (outer JSON with inner JSON payload)
      '^\{\s*"@timestamp"\s*=>\s*%{TIMESTAMP_ISO8601:timestamp},\s*"severity"\s*=>\s*"%{WORD:severity}",\s*"time"\s*=>\s*"%{DATA:sys_time}",\s*"message"\s*=>\s*"%{GREEDYDATA:json_message}",\s*"type"\s*=>\s*"%{WORD:type}",\s*"service"\s*=>\s*"%{WORD:service}"\s*\}$',

      # [5] Auth (Django) HTTP access logs
      '^\{\s*"@timestamp"\s*=>\s*%{TIMESTAMP_ISO8601:timestamp},\s*"severity"\s*=>\s*"%{WORD:severity}",\s*"time"\s*=>\s*"%{DATA:sys_time}",\s*"message"\s*=>\s*"%{TIME:log_time2},%{INT:ms}\s+%{LOGLEVEL:level2}\s+%{DATA:logger2}\s+\"%{WORD:verb}\s+%{URIPATH:request}(?:\s+HTTP\/%{NUMBER:http_version})?\"\s+%{NUMBER:status}\s+%{NUMBER:bytes}\",\s*"type"\s*=>\s*"%{WORD:type}",\s*"service"\s*=>\s*"%{WORD:service}"\s*\}$',

      # [6] Nginx access logs (common log format)
      '%{IP:client_ip} - - \[%{HTTPDATE:nginx_timestamp}\] "(?<verb_nginx>GET|POST|PUT|DELETE|HEAD) %{URIPATH:nginx_request}(?: HTTP\/%{NUMBER:nginx_http_version})?" %{NUMBER:nginx_status} %{NUMBER:nginx_bytes} "(?<referrer>[^"]*)" "(?<agent>[^"]*)"',
      
      # [7] nginx_exporter logs (assumed JSON-like)
      '^\{\s*"@timestamp"\s*=>\s*%{TIMESTAMP_ISO8601:timestamp},\s*"service"\s*=>\s*"(nginx_exporter)",\s*"message"\s*=>\s*"%{GREEDYDATA:msg}".*\}$',
      
      # [8] postgres_exporter logs (assumed JSON-like)
      '^\{\s*"@timestamp"\s*=>\s*%{TIMESTAMP_ISO8601:timestamp},\s*"service"\s*=>\s*"(postgres_exporter)",\s*"message"\s*=>\s*"%{GREEDYDATA:msg}".*\}$',
      
      # [9] PostgreSQL service logs (common PostgreSQL log format)
      '^\[%{TIMESTAMP_ISO8601:timestamp}\]\s+\[%{WORD:pg_log_level}\]\s+%{DATA:component}:\s+%{GREEDYDATA:msg}$',
      
      # [10] Prometheus logs (key/value format)
      '^level=%{WORD:level}\s+ts=%{TIMESTAMP_ISO8601:timestamp}\s+msg="(?<message>[^"]+)"(?:\s+job=%{DATA:job})?.*$'
    ] }
  }

  # For Elastic logs: if json_message exists, parse it as JSON into "elastic_data"
  if [json_message] {
    json {
      source => "json_message"
      target => "elastic_data"
      remove_field => ["json_message"]
    }
  }

  mutate {
    remove_field => ["event", "host", "@version", "app", "json_payload", "severity"]
  }
  
  # Drop events that do not have a "service" field.
  if ![service] {
    drop { }
  }

  # Drop events that have a grok parse failure.
  if "grokparsefailure" in [tags] {
    drop { }
  }
}

output {
  elasticsearch {
    hosts => ["https://elasticsearch:9200"]
    index => "%{service}-%{+YYYY.MM.dd}"
    user => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}"
    ssl_enabled => true
    ssl_certificate_authorities => "/usr/share/logstash/certs/ca/ca.crt"
  }
  stdout { codec => rubydebug }
}
